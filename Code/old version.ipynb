{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sksurv.preprocessing import OneHotEncoder\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_column',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_by_index(X,indexes):\n",
    "    \"\"\"\n",
    "    helper function to drop rows of dataframe and return new dataframe without those rows with indexes resetted\n",
    "    \"\"\"\n",
    "    X = X.drop(indexes)\n",
    "    X = X.reset_index().drop(columns=\"index\")\n",
    "    return(X)\n",
    "\n",
    "def dataSetting(dropCol,FILE_FOLDER = \"C:\\\\SMU_v2\\\\\"):\n",
    "    '''\n",
    "    function to read the pkl from from datasource\n",
    "        1. Remove dx_date that is NULL.\n",
    "        2. Drop all rows where crucial fields for X_features are NULL.\n",
    "        3. Convert Date columns into datetime format\n",
    "        4. Derive OS, CSS, DFS days based on dx_date\n",
    "        5. Create status column to indicate if the patient is dead or alive base on if death_age exists\n",
    "    '''\n",
    "    df = pd.read_pickle(FILE_FOLDER + \"clinical_output.pkl\").reset_index().drop(columns=\"index\")\n",
    "    to_drop = df[df['dx_date']==\"NA\"].index\n",
    "    df = drop_by_index(df,to_drop)\n",
    "\n",
    "    df.drop(columns=dropCol,inplace = True)\n",
    "\n",
    "    # drop all rows where dates are null\n",
    "    df.dropna(axis=0,\\\n",
    "                    subset=['Date_for_DFS','Date_for_OS','Date_for_CSS','dx_date','size_precise', 'nodespos'],\\\n",
    "                    inplace=True)\n",
    "    # convert all datetime in dataframe into dateime format for processing\n",
    "    df[\"Date_for_DFS\"] = pd.to_datetime(df[\"Date_for_DFS\"])\n",
    "    df[\"Date_for_OS\"] = pd.to_datetime(df[\"Date_for_OS\"])\n",
    "    df[\"Date_for_CSS\"] = pd.to_datetime(df[\"Date_for_CSS\"])\n",
    "    df[\"dx_date\"] = pd.to_datetime(df[\"dx_date\"])\n",
    "    df['last_seen']= pd.to_datetime(df[\"dx_date\"])\n",
    "\n",
    "    # calculate in days\n",
    "    df[\"DFS_days\"] = (df[\"Date_for_DFS\"] - df['dx_date'] )/np.timedelta64(1, 'D')\n",
    "    df[\"OS_days\"] = (df[\"Date_for_OS\"] - df['dx_date'] )/np.timedelta64(1, 'D')\n",
    "    df[\"CSS_days\"] = (df[\"Date_for_CSS\"] - df['dx_date'] )/np.timedelta64(1, 'D')\n",
    "\n",
    "    # alive or dead\n",
    "    df['status'] = np.where(df['Count_as_OS'].isnull(), False, True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def ComputeYears(df, Year_list):\n",
    "    '''\n",
    "    Create a list to contain df for different years of survival\n",
    "    The df will filter those patient that has deceased or days of survival longer than the defined years.\n",
    "    '''\n",
    "\n",
    "    df_dict = {}\n",
    "    for i in Year_list:\n",
    "        tmp = {}\n",
    "        for x in list([\"DFS\", \"CSS\", \"OS\"]):\n",
    "            df['{}_{}_years'.format(x, i)] = np.where(\n",
    "                                                      np.logical_or(df['death_age'] > 0,\\\n",
    "                                                      df['{}_days'.format(x)]/(365.25*i) >= i),\\\n",
    "                                                      True,False)\n",
    "            tmp[x] = df[df['{}_{}_years'.format(x, i)] == True]\n",
    "        df_dict['{}_years'.format(i)] = tmp\n",
    "    return df_dict\n",
    "\n",
    "def settingXY(df_dict, X_features, Y_features, YEAR, STYPE, OHE_LOCATION = \"C:\\\\SMU_v2\\\\\"):\n",
    "    '''\n",
    "    This function returns the X and Y features need for model training\n",
    "        - The function also generates one pkl that contains the One Hot Encoder for new raw data \n",
    "    \n",
    "    X_features = features to use for X\n",
    "    Y_features = features to use for Y \n",
    "    YEAR = years of patient record interested\n",
    "    SYTPE = survival type (OS, DFS, CSS)\n",
    "    OHE_LOCATION = location to store the pkl file\n",
    "    '''\n",
    "    import pickle\n",
    "    \n",
    "    DF_TO_USE = df_dict['{}_years'.format(YEAR)][STYPE]\n",
    "\n",
    "    X = DF_TO_USE[X_features]\n",
    "    Y = DF_TO_USE[Y_features]\n",
    "    # convert to int since some fields fro age_@_dx is null\n",
    "    X.loc[:,\"Age_@_Dx\"] = X[\"Age_@_Dx\"].astype(\"int16\")\n",
    "\n",
    "    # Save enconder so that we can OHE new data\n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(X)\n",
    "    \n",
    "    # OHE for probability\n",
    "    X = enc.transform(X)\n",
    "    with open(OHE_LOCATION + 'encoder.pickle', 'wb') as f:\n",
    "        pickle.dump(enc, f) \n",
    "                  \n",
    "    # convert Y to structured array\n",
    "    s = Y.dtypes\n",
    "    Y = np.array([tuple(x) for x in Y.values], dtype=list(zip(s.index, s)))\n",
    "   \n",
    "    return X, Y\n",
    "\n",
    "def train_test(X, Y, test_size = 0.33, random_state = 42,):\n",
    "    '''\n",
    "    Splitting the dataset into the Training set and Test set\n",
    "    '''\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y,  test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "def Cox(X_train,Y_train,alpha = 1e-4, verbose = 0):\n",
    "        \n",
    "    # since features are highly corelated, reducing alpha values to smaller values allows the learning\n",
    "    model = CoxPHSurvivalAnalysis(alpha = alpha, verbose = verbose)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    '''\n",
    "    In survival analysis, the hazard ratio (HR) is the ratio of the hazard rates corresponding\n",
    "    to the conditions described by two levels of an explanatory variable. \n",
    "        For example, in a drug study, the treated population may die at twice the rate per unit time\n",
    "        as the control population. The hazard ratio would be 2, indicating higher hazard of death from the treatment. \n",
    "        Or in another study, men receiving the same treatment may suffer a certain complication ten times more\n",
    "        frequently per unit time than women, giving a hazard ratio of 10. - wiki\n",
    "    '''\n",
    "    tmp = pd.Series(model.coef_, index=X_train.columns)\n",
    "    tmp = tmp.to_frame(\"Log Hazarad Ratio\")\n",
    "    tmp = tmp.sort_values(by=['Log Hazarad Ratio'])\n",
    "    \n",
    "    return model, tmp\n",
    "\n",
    "def fit_and_score_features(X, y):\n",
    "    '''\n",
    "    Based on the Cox model, rank the scores of each feature to understand which X features plays the key role in\n",
    "    modelling\n",
    "    '''\n",
    "    n_features = X.shape[1]\n",
    "    scores = np.empty(n_features)\n",
    "    m = CoxPHSurvivalAnalysis(alpha = 1e-4)\n",
    "    for j in range(n_features):\n",
    "        Xj = X[:, j:j+1]\n",
    "        m.fit(Xj, y)\n",
    "        scores[j] = m.score(Xj, y)\n",
    "    return scores\n",
    "\n",
    "def loadOHE(df,OHE_LOCATION = \"C:\\\\SMU_v2\\\\\"):\n",
    "    '''\n",
    "    load enconder to OHE new raw data for prediction\n",
    "    '''\n",
    "    import pickle\n",
    "    with open(OHE_LOCATION + 'encoder.pickle', 'rb') as f:\n",
    "        enc = pickle.load(f) \n",
    "    \n",
    "    #type case object to category\n",
    "    typeCastList = list(df.select_dtypes(include=[object]).columns)\n",
    "    df[typeCastList] = df[typeCastList].astype(\"category\")\n",
    "    OHE_New_Data = enc.transform(df)\n",
    "    \n",
    "    return OHE_New_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Count_as_OS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Count_as_OS'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6131b4b4fda6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m               'Count_as_DFS','Count_as_OS','Count_as_CSS']\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclinical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataSetting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlistToDrop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0myear_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mComputeYears\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclinical\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myear_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-e7c4a29162cc>\u001b[0m in \u001b[0;36mdataSetting\u001b[1;34m(dropCol, FILE_FOLDER)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# alive or dead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'status'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Count_as_OS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2994\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2995\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2996\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Count_as_OS'"
     ]
    }
   ],
   "source": [
    "listToDrop = ['NRIC','dob','Has Bills?','Side','Hospital','KKH','NCCS','SGH',\\\n",
    "              'Count_as_DFS','Count_as_CSS']\n",
    "\n",
    "clinical = dataSetting(listToDrop)\n",
    "year_list = list([1,5,10])\n",
    "df_dict = ComputeYears(clinical,year_list)\n",
    "YEAR = 1\n",
    "STYPE = \"OS\"\n",
    "x_features = list(['tstage','nstage', 'Mstage', 'ER', 'PR', 'Her2', 'size_precise', 'nodespos', 'Age_@_Dx'])\n",
    "y_features = list(['status','OS_days'])\n",
    "\n",
    "X, Y = settingXY(df_dict, x_features, y_features, YEAR, STYPE)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test(X, Y)\n",
    "\n",
    "print(\"X shape: {}\".format(X.shape))\n",
    "print(\"Y shape: {}\".format(Y.shape))\n",
    "\n",
    "\n",
    "CoxEstimator, Log_Hazard_Ratio = Cox(X,Y)\n",
    "\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "prediction = CoxEstimator.predict(X_test)\n",
    "result = concordance_index_censored(Y_test[\"status\"], Y_test[\"OS_days\"], prediction)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "\n",
    "random_state = 20\n",
    "rsf = RandomSurvivalForest(n_estimators=1000,\n",
    "                           min_samples_split=10,\n",
    "                           min_samples_leaf=15,\n",
    "                           max_features=\"sqrt\",\n",
    "                           n_jobs=-1,\n",
    "                           random_state=random_state)\n",
    "rsf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
