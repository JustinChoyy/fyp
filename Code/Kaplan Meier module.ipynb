{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_column',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KM_to_df(KM_object):\n",
    "    \n",
    "    # Process the summary as string\n",
    "    \n",
    "    summary_lines_list = str(KM_object.summary).split(\"\\n\")\n",
    "    \n",
    "    header = [\"time\", \"events\", \"at_risk\",  \"estimate\",  \"std_error\",  \"95%_CI_lower\",  \"95%_CI_upper\"]\n",
    "    rows = summary_lines_list[6:]\n",
    "    \n",
    "    row_values = []\n",
    "    \n",
    "    for row in rows:\n",
    "        \n",
    "        elements = row.split(\" \")\n",
    "        tmp = []\n",
    "        for element in elements:\n",
    "            if element.isnumeric() or (\".\" in element):\n",
    "                tmp.append(element)\n",
    "                \n",
    "        row_values.append(tmp)\n",
    "        \n",
    "    #Build df\n",
    "    output_df = pd.DataFrame(row_values, columns=header)\n",
    "                \n",
    "    return output_df\n",
    "\n",
    "def drop_by_index(X,indexes):\n",
    "    \"\"\"\n",
    "    helper function to drop rows of dataframe and return new dataframe without those rows with indexes resetted\n",
    "    \"\"\"\n",
    "    X = X.drop(indexes)\n",
    "    X = X.reset_index().drop(columns=\"index\")\n",
    "    return(X)\n",
    "\n",
    "def build_surv_obj(survival_type, years, df_dict):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function builds the survival object to be processed by kaplan meier model to return kaplan meier df\n",
    "    \"\"\"\n",
    "    \n",
    "    survival_type = str(survival_type)\n",
    "    years = str(years)\n",
    "    \n",
    "    survival_df = df_dict[years + \"_years\"][survival_type]\n",
    "    \n",
    "    Time_df = survival_df.loc[:,[survival_type + \"_days\"]]\n",
    "    Time_df[survival_type + \"_years\"] = Time_df[survival_type + \"_days\"]/365.25\n",
    "    Time_df[\"status\"] = survival_df[\"status_\" + survival_type]\n",
    "    Time_df.head()\n",
    "\n",
    "    return SurvivalData(time= (survival_type+ \"_years\"), status=\"status\", data=Time_df)\n",
    "\n",
    "def ComputeYears(df, Year_list):\n",
    "    '''\n",
    "    Create a list to contain df for different years of survival\n",
    "    The df will filter those patient that has deceased or days of survival longer than the defined years.\n",
    "    '''\n",
    "\n",
    "    df_dict = {}\n",
    "\n",
    "    for i in Year_list:\n",
    "        tmp = {}\n",
    "        for x in list([\"DFS\", \"CSS\", \"OS\"]):\n",
    "            df['{}_{}_years'.format(x, i)] = np.where(\n",
    "                                                      np.logical_or(df['death_age'] > 0,\\\n",
    "                                                      df['{}_days'.format(x)]/(365.25*i) >= i),\\\n",
    "                                                      True,False)\n",
    "            tmp[x] = df[df['{}_{}_years'.format(x, i)] == True]\n",
    "        df_dict['{}_years'.format(i)] = tmp\n",
    "    return df_dict\n",
    "\n",
    "def dataSetting(dropCol,FILE_FOLDER = \"C:\\\\SMU_v2\\\\\"):\n",
    "    '''\n",
    "    function to read the pkl from from datasource\n",
    "        1. Remove dx_date that is NULL.\n",
    "        2. Drop all rows where crucial fields for X_features are NULL.\n",
    "        3. Convert Date columns into datetime format\n",
    "        4. Derive OS, CSS, DFS days based on dx_date\n",
    "        5. Create status column to indicate if the patient is dead or alive base on if death_age exists\n",
    "    '''\n",
    "    df = pd.read_pickle(FILE_FOLDER + \"clinical_output.pkl\").reset_index().drop(columns=\"index\")\n",
    "    to_drop = df[df['dx_date']==\"NA\"].index\n",
    "    df = drop_by_index(df,to_drop)\n",
    "\n",
    "    df.drop(columns=dropCol,inplace = True)\n",
    "\n",
    "    # drop all rows where dates are null\n",
    "    df.dropna(axis=0,\\\n",
    "                    subset=['Date_for_DFS','Date_for_OS','Date_for_CSS','dx_date','size_precise', 'nodespos'],\\\n",
    "                    inplace=True)\n",
    "\n",
    "    # convert all datetime in dataframe into dateime format for processing\n",
    "    df[\"Date_for_DFS\"] = pd.to_datetime(df[\"Date_for_DFS\"])\n",
    "    df[\"Date_for_OS\"] = pd.to_datetime(df[\"Date_for_OS\"])\n",
    "    df[\"Date_for_CSS\"] = pd.to_datetime(df[\"Date_for_CSS\"])\n",
    "    df[\"dx_date\"] = pd.to_datetime(df[\"dx_date\"])\n",
    "    df['last_seen']= pd.to_datetime(df[\"dx_date\"])\n",
    "\n",
    "    # calculate in days\n",
    "    df[\"DFS_days\"] = (df[\"Date_for_DFS\"] - df['dx_date'] )/np.timedelta64(1, 'D')\n",
    "    df[\"OS_days\"] = (df[\"Date_for_OS\"] - df['dx_date'] )/np.timedelta64(1, 'D')\n",
    "    df[\"CSS_days\"] = (df[\"Date_for_CSS\"] - df['dx_date'] )/np.timedelta64(1, 'D')\n",
    "\n",
    "    # alive or dead\n",
    "    df['status_OS'] = np.where(df['Count_as_OS'] != \"N\", True, False)\n",
    "    df['status_DFS'] = np.where(df['Count_as_DFS'] != \"N\", True, False)\n",
    "    df['status_CSS'] = np.where(df['Count_as_CSS'] != \"N\", True, False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def layeredData(df, group_dict,y_features, YEAR, STYPE):\n",
    "    \n",
    "    '''\n",
    "        this function generates the dataframe required for specific groups we hope to analyze\n",
    "        there are total 3 different groups but group 3 consist of multiple subgroups which leads a total of 5\n",
    "        dataframe.\n",
    "        Group 1: patient with stage 4 cancer\n",
    "        Group 2: patient which unknown records or at initial diagnosis stage\n",
    "        Group 3: make up of patient that does not belong to the groups above\n",
    "    '''\n",
    "    model_data_dict = {}\n",
    "    TO_USE = df['{}_years'.format(YEAR)][STYPE]\n",
    "    \n",
    "    print(\"Overall initial size: {} \\n\".format(TO_USE.shape[0]))\n",
    "        \n",
    "    for key,value in group_dict.items():\n",
    "        TO_USE_COPY = TO_USE.copy()\n",
    "\n",
    "        tmp = {}\n",
    "        \n",
    "        waves = value['wave']\n",
    "    \n",
    "        if key != \"group 3\":\n",
    "            # for group 1 and group 2 select rows that contains either stage 4/non invasive in Stage\n",
    "            TO_USE_COPY = TO_USE_COPY.loc[TO_USE_COPY['Stage'] == group_dict[key]['stage'][0]]\n",
    "        else:\n",
    "            # for group 3 do not select rows that contains either stage 4 or non invasive in c_Staging or p_Staging\n",
    "            stage = np.logical_and(TO_USE_COPY['Stage'] != group_dict[key]['stage'][0],\\\n",
    "                                    TO_USE_COPY['Stage'] != group_dict[key]['stage'][1])\n",
    "            \n",
    "            TO_USE_COPY = TO_USE_COPY.loc[stage]\n",
    "            \n",
    "        print(\"{} data size: {}\".format(key,len(TO_USE_COPY)))\n",
    "        \n",
    "        for wave in waves:\n",
    "            TO_USE_COPY2 = TO_USE_COPY.copy()\n",
    "            TO_USE_COPY2 = TO_USE_COPY2[waves[wave] + y_features]\n",
    "            \n",
    "            len_before = len(TO_USE_COPY2)\n",
    "            print(\"\\t{} data size before dropping nan: {}\".format(wave,len_before))\n",
    "            \n",
    "            TO_USE_COPY2.dropna(axis=0,subset=waves[wave]+ y_features, inplace=True)\n",
    "            TO_USE_COPY2.reset_index(drop=True)\n",
    "\n",
    "            len_after = len(TO_USE_COPY2)\n",
    "            print(\"\\t\\t after dropping nan: {}\".format(len_after))\n",
    "            \n",
    "            for i in waves[wave]:\n",
    "                if not (i in ['nodespos','Age_@_Dx','size_precise']):\n",
    "                    TO_USE_COPY2.loc[:,i] = TO_USE_COPY2[i].astype(\"category\")\n",
    "                else:\n",
    "                    TO_USE_COPY2.loc[:,i] = TO_USE_COPY2[i].astype(\"float32\")\n",
    "            \n",
    "            X, Y = settingXY(TO_USE_COPY2, waves[wave], y_features,name= \"{}_{}\".format(key,wave))   \n",
    "\n",
    "            tmp[wave] = {\n",
    "                            \"X\": X,\\\n",
    "                            \"Y\":Y      \n",
    "                        }    \n",
    "    \n",
    "        model_data_dict[key] = tmp\n",
    "    return model_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "listToDrop = ['NRIC','dob','Has Bills?','Side','Hospital','KKH','NCCS','SGH']\n",
    "\n",
    "clinical = dataSetting(listToDrop)\n",
    "\n",
    "year_list = list([1,5,10])\n",
    "df_dict = ComputeYears(clinical,year_list)\n",
    "y_features = []\n",
    "\n",
    "YEAR = 1\n",
    "STYPE = \"OS\"\n",
    "\n",
    "group_dict = { \n",
    "                \"group 1\": {\n",
    "                             \"stage\": ['stage 4'],\\\n",
    "                             'wave': {\n",
    "                                         \"layer 1\": ['Age_@_Dx', 'diff', 'ER', 'PR','Her2','Stage'],\\\n",
    "                                         \"layer 2\": ['Age_@_Dx', 'diff', 'ER', 'PR','Her2',\\\n",
    "                                                     'T (no subgroup)', 'N (no subgroup)'],\\\n",
    "                                         \"layer 3\": ['Age_@_Dx', 'diff', 'ER', 'PR','Her2', 'T', 'N'],\\\n",
    "                                         \"layer 4\": ['Age_@_Dx', 'diff', 'ER', 'PR','Her2', 'size_precise', 'nodespos']\n",
    "                                     }\n",
    "                           },\\\n",
    "                \"group 2\": {\n",
    "                             'stage': ['dcis/lcis non-invasive'],\\\n",
    "                             'wave': {\n",
    "                                         \"layer 1\": ['Age_@_Dx', 'diff', 'ER', 'PR','Her2','Size'],\\\n",
    "                                         \"layer 2\": ['Age_@_Dx', 'diff', 'ER', 'PR','Her2','size_precise']\n",
    "                                     }\n",
    "                           },\\\n",
    "                \"group 3\": {\n",
    "                             \"stage\": ['stage 4','dcis/lcis non-invasive'],\\\n",
    "                             'wave': {\n",
    "                                         \"layer 1\": ['Age_@_Dx', 'diff', 'ER', 'PR','Her2','Stage'],\\\n",
    "                                         \"layer 2\": ['Age_@_Dx', 'diff', 'ER', 'PR','Her2',\\\n",
    "                                                     'T (no subgroup)', 'N (no subgroup)', 'M (no subgroup)'],\\\n",
    "                                         \"layer 3\": ['Age_@_Dx', 'diff', 'ER', 'PR','Her2', 'T', 'N', 'M'],\\\n",
    "                                         \"layer 4\": ['Age_@_Dx', 'diff', 'ER', 'PR','Her2', 'size_precise',\\\n",
    "                                                     'nodespos','M']\n",
    "                                     }\n",
    "                           },\n",
    "                }\n",
    "\n",
    "# Display shape of data after filtering\n",
    "# for i in df_dict:\n",
    "#     for s_type in df_dict[i]:\n",
    "#         print(\"Year: {}, survival category: {}, size: {}\".format(i,s_type,df_dict[i][s_type].shape))\n",
    "    \n",
    "model_data_dict = layeredData(df_dict, group_dict,y_features,YEAR, STYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict[\"10_years\"][\"OS\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaplan Meier Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\", palette=\"colorblind\", color_codes=True)\n",
    "\n",
    "from survive import datasets\n",
    "from survive import SurvivalData\n",
    "from survive import KaplanMeier, Breslow, NelsonAalen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall Survival Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Input DF\n",
    "surv = build_surv_obj(survival_type=\"OS\", years=10, df_dict=df_dict)\n",
    "OS_km = KaplanMeier()\n",
    "OS_km.fit(surv)\n",
    "\n",
    "#Plot Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "OS_km.plot()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = KM_to_df(OS_km)\n",
    "o.to_csv(\"C:\\\\Users\\\\LINGXING\\\\Desktop\\\\GIT\\\\fyp\\\\Code\\\\km.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = pd.read_csv(\"C:\\\\Users\\\\LINGXING\\\\Desktop\\\\GIT\\\\fyp\\\\Code\\\\km.csv\")\n",
    "i.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disease Free Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Input DF\n",
    "surv = build_surv_obj(survival_type=\"DFS\",years=10, df_dict=df_dict)\n",
    "DFS_km = KaplanMeier()\n",
    "DFS_km.fit(surv)\n",
    "print(DFS_km.summary)\n",
    "print(DFS_km)\n",
    "\n",
    "#Plot curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "DFS_km.plot()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "#Estimate is basically reading off the curve at the respective time\n",
    "estimate = DFS_km.predict([0.002738,1,2,3,4,5,6,7,8,9,10])\n",
    "display(estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cancer Specific Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Input DF\n",
    "surv = build_surv_obj(survival_type=\"CSS\", years=10, df_dict=df_dict)\n",
    "CSS_km = KaplanMeier()\n",
    "CSS_km.fit(surv)\n",
    "# print(CSS_km.summary)\n",
    "print(CSS_km)\n",
    "\n",
    "#Plot curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "CSS_km.plot()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
